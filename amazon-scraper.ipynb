{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon price scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url(search_term, page):\n",
    "    #Generate a url from search text\n",
    "    template = \"https://www.amazon.com.tr/s?k={}&page={}&__mk_tr_TR=%C3%85M%C3%85%C5%BD%C3%95%C3%91&crid=6B9N7CEYX8L5&qid=1730488024&ref=sr_pg_{}\"\n",
    "    search_term = search_term.replace(\" \", \"+\")\n",
    "    url = template.format(search_term, page, page)\n",
    "        \n",
    "    return url\n",
    "\n",
    "# Mapping of Turkish keys to English equivalents (translated versions of scrapped product information headers in Turkish )\n",
    "# Sometimes products don't have every field in here and/or have additional different fields\n",
    "# These are just some of the common ones I chose to get for products that have them\n",
    "translation_dict = {\n",
    "    \"Marka\": \"Brand\",\n",
    "    \"Üretici\": \"Manufacturer\",\n",
    "    \"Paket Boyutları\": \"Package Dimensions\",\n",
    "    \"Üretici Referansı\": \"Manufacturer Reference\",\n",
    "    \"Çözünürlük\": \"Resolution\",\n",
    "    \"İşlemci Markası\": \"Processor Brand\",\n",
    "    \"İşlemci Türü\": \"Processor Type\",\n",
    "    \"İşlemci Hızı\": \"Processor Speed\",\n",
    "    \"RAM Boyutu\": \"RAM Size\",\n",
    "    \"Bilgisayar Bellek Türü\": \"Computer Memory Type\",\n",
    "    \"Sabit Sürücü Boyutu\": \"Hard Drive Size\",\n",
    "    \"Sabit Disk Açıklaması\": \"Hard Drive Description\",\n",
    "    \"Sabit Sürücü Arabirimi\": \"Hard Drive Interface\",\n",
    "    \"Grafik İşlemci Üreticisi\": \"Graphics Processor Manufacturer\",\n",
    "    \"Kablosuz Türü\": \"Wireless Type\",\n",
    "    \"Voltaj\": \"Voltage\",\n",
    "    \"İşletim Sistemi\": \"Operating System\",\n",
    "    \"ASIN\": \"ASIN\",\n",
    "    \"Ürün Ağırlığı\": \"Product Weight\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_record(item, driver):\n",
    "    \n",
    "    #Extract and return data from a single record\n",
    "    \n",
    "    # description and url\n",
    "    atag = item.h2.a\n",
    "    description = atag.text.strip()\n",
    "    url = \"https://www.amazon.com.tr\" + atag.get(\"href\")\n",
    "    \n",
    "    rating = ''\n",
    "    review_count = ''\n",
    "    star_5_text = ''\n",
    "    star_4_text = ''\n",
    "    star_3_text = ''\n",
    "    star_2_text = ''\n",
    "    star_1_text = ''\n",
    "    release_date = ''\n",
    "    \n",
    "    try:\n",
    "        # product price\n",
    "        price_parent = item.find('span', 'a-price')\n",
    "        price = price_parent.find('span', 'a-offscreen').text\n",
    "    except AttributeError:\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        # rating and review count\n",
    "        rating = item.i.text\n",
    "        review_count = item.find('div', {'data-cy': 'reviews-block'}).find('span', {'class': 'a-size-base s-underline-text'}).text\n",
    "    except AttributeError:\n",
    "        pass # Leave rating and review_count as empty strings if not found\n",
    "    \n",
    "    \n",
    "        \n",
    "    # Go to the product page to extract additional details\n",
    "    driver.get(url)\n",
    "    time.sleep(10)  # Allow page to load fully\n",
    "    product_soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    \n",
    "        \n",
    "    # Extract full text of star rating elements (purposefully left uncleaned)\n",
    "    try:\n",
    "        # Locate the rating elements within the histogram table \n",
    "        rating_elements = product_soup.find('ul', id='histogramTable')\n",
    "        \n",
    "        if rating_elements:\n",
    "            for li in rating_elements.find_all('li'):\n",
    "                # Find either an <a> or <span> tag with aria-label attribute\n",
    "                anchor_or_span = li.find(['a', 'span'], {'aria-label': True})\n",
    "                \n",
    "                if anchor_or_span:\n",
    "                    label = anchor_or_span['aria-label'].strip()\n",
    "                    \n",
    "                    # Check for star level and assign the label to the appropriate variable\n",
    "                    if \"5 yıldız\" in label:\n",
    "                        star_5_text = label\n",
    "                    elif \"4 yıldız\" in label:\n",
    "                        star_4_text = label\n",
    "                    elif \"3 yıldız\" in label:\n",
    "                        star_3_text = label\n",
    "                    elif \"2 yıldız\" in label:\n",
    "                        star_2_text = label\n",
    "                    elif \"1 yıldız\" in label:\n",
    "                        star_1_text = label\n",
    "    except AttributeError:\n",
    "        pass  # If rating elements are not found, leave star texts as empty\n",
    "    \n",
    "    \n",
    "    # Locate the release date from the details table\n",
    "    try:\n",
    "        details_table = product_soup.find('table', id='productDetails_detailBullets_sections1')\n",
    "        if details_table:\n",
    "            for row in details_table.find_all('tr'):\n",
    "                header = row.find('th', 'a-color-secondary')\n",
    "                if header and \"Satışa Sunulduğu İlk Tarih\" in header.text.strip():\n",
    "                    release_date = row.find('td', class_='a-size-base').text.strip()\n",
    "                    break\n",
    "    except AttributeError:\n",
    "        pass  # If release date is not found, leave it as an empty string\n",
    "\n",
    "\n",
    "    # Extract technical specifications with translation\n",
    "    tech_specs = {}\n",
    "    try:\n",
    "        tech_spec_table = product_soup.find('table', id='productDetails_techSpec_section_1')\n",
    "        if tech_spec_table:\n",
    "            for row in tech_spec_table.find_all('tr'):\n",
    "                header = row.find('th', 'a-color-secondary a-size-base prodDetSectionEntry')\n",
    "                value = row.find('td', 'a-size-base prodDetAttrValue')\n",
    "                if header and value:\n",
    "                    key = header.text.strip()\n",
    "                    translated_key = translation_dict.get(key)  # Map only if in translation_dict\n",
    "                    if translated_key:  # Include only keys found in the dictionary\n",
    "                        tech_specs[translated_key] = value.text.strip()\n",
    "    except AttributeError:\n",
    "        pass  # Leave tech_specs empty if no valid table found\n",
    "\n",
    "\n",
    "\n",
    "    # Compile result\n",
    "    result = {\n",
    "        \"Description\": description,\n",
    "        \"Price\": price,\n",
    "        \"Rating\": rating,\n",
    "        \"ReviewCount\": review_count,\n",
    "        \"Url\": url,\n",
    "        \"5StarPct\": star_5_text,\n",
    "        \"4StarPct\": star_4_text,\n",
    "        \"3StarPct\": star_3_text,\n",
    "        \"2StarPct\": star_2_text,\n",
    "        \"1StarPct\": star_1_text,\n",
    "        \"ReleaseDate\": release_date,\n",
    "    }\n",
    "    result.update(tech_specs)  # Add tech specs as additional columns\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(search_term):\n",
    "    \n",
    "    # Startup the webdriver\n",
    "    driver = webdriver.Chrome()\n",
    "    records = []\n",
    "\n",
    "    # Second number in range should be adjusted manually according to the search term \n",
    "    # and how many pages of results there are for it\n",
    "    for page in range(1, 5):\n",
    "        url = get_url(search_term, page)\n",
    "        driver.get(url)\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        results = soup.find_all('div', {'data-component-type': 's-search-result'})\n",
    "        for item in results:\n",
    "            record = extract_record(item, driver)\n",
    "            if record:\n",
    "                records.append(record)\n",
    "    \n",
    "    driver.close()\n",
    "\n",
    "    # Save data to CSV\n",
    "    if records:\n",
    "        # Use only predefined keys\n",
    "        predefined_keys = [\n",
    "            \"Description\", \"Price\", \"Rating\", \"ReviewCount\", \"Url\",\n",
    "            \"5StarPct\", \"4StarPct\", \"3StarPct\", \"2StarPct\", \"1StarPct\", \"ReleaseDate\"\n",
    "        ] + list(translation_dict.values())  # Combine with translated keys\n",
    "        fieldnames = predefined_keys\n",
    "        with open('output.csv', 'w', newline='', encoding='utf-8-sig') as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            writer.writerows(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run program with any search item granted page number in main function is adjusted properly\n",
    "main('laptop')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
